{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","authorship_tag":"ABX9TyOX98Zgnt4RRswcUcodi3ez"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import requests\n","\n","def download_csv(url, save_path):\n","    response = requests.get(url)\n","\n","    # 홈페이지에서 제대로 응답을 받았는지 확인\n","    response.raise_for_status()\n","\n","    with open(save_path, 'wb') as f:\n","        f.write(response.content)\n","\n","    print(f\"CSV file downloaded and saved as {save_path}\")\n","\n","# 사용 예시\n","url = 'https://example.com/data.csv'\n","save_path = 'local_path/data.csv'\n","download_csv(url, save_path)"],"metadata":{"id":"5jVRtp22ynoD"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"rFjGJAqG9aA8","executionInfo":{"status":"ok","timestamp":1694406536271,"user_tz":-540,"elapsed":36031,"user":{"displayName":"띵현","userId":"11430659926875687373"}},"outputId":"9a669b72-93ec-4e74-cfe0-9950e84c3db2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorflow-gpu==2.8.0rc0\n","  Downloading tensorflow_gpu-2.8.0rc0-cp310-cp310-manylinux2010_x86_64.whl (492.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m492.2/492.2 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-gpu==2.8.0rc0) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-gpu==2.8.0rc0) (1.6.3)\n","Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow-gpu==2.8.0rc0) (23.5.26)\n","Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-gpu==2.8.0rc0) (0.4.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-gpu==2.8.0rc0) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-gpu==2.8.0rc0) (3.9.0)\n","Collecting keras-preprocessing>=1.1.1 (from tensorflow-gpu==2.8.0rc0)\n","  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-gpu==2.8.0rc0) (16.0.6)\n","Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow-gpu==2.8.0rc0) (1.23.5)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow-gpu==2.8.0rc0) (3.3.0)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow-gpu==2.8.0rc0) (3.20.3)\n","Collecting setuptools<60 (from tensorflow-gpu==2.8.0rc0)\n","  Downloading setuptools-59.8.0-py3-none-any.whl (952 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m952.8/952.8 kB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-gpu==2.8.0rc0) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-gpu==2.8.0rc0) (2.3.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow-gpu==2.8.0rc0) (4.5.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-gpu==2.8.0rc0) (1.15.0)\n","Collecting tensorboard<2.8,>=2.7 (from tensorflow-gpu==2.8.0rc0)\n","  Downloading tensorboard-2.7.0-py3-none-any.whl (5.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m71.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tf-estimator-nightly==2.8.0.dev2021122109 (from tensorflow-gpu==2.8.0rc0)\n","  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.5/462.5 kB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting keras<2.9,>=2.8.0rc0 (from tensorflow-gpu==2.8.0rc0)\n","  Downloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m90.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-gpu==2.8.0rc0) (0.33.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow-gpu==2.8.0rc0) (1.57.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow-gpu==2.8.0rc0) (0.41.2)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.8,>=2.7->tensorflow-gpu==2.8.0rc0) (2.17.3)\n","Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.8,>=2.7->tensorflow-gpu==2.8.0rc0)\n","  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.8,>=2.7->tensorflow-gpu==2.8.0rc0) (3.4.4)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.8,>=2.7->tensorflow-gpu==2.8.0rc0) (2.31.0)\n","Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.8,>=2.7->tensorflow-gpu==2.8.0rc0)\n","  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m110.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0 (from tensorboard<2.8,>=2.7->tensorflow-gpu==2.8.0rc0)\n","  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.8,>=2.7->tensorflow-gpu==2.8.0rc0) (2.3.7)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.8,>=2.7->tensorflow-gpu==2.8.0rc0) (5.3.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.8,>=2.7->tensorflow-gpu==2.8.0rc0) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.8,>=2.7->tensorflow-gpu==2.8.0rc0) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.8,>=2.7->tensorflow-gpu==2.8.0rc0) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.8,>=2.7->tensorflow-gpu==2.8.0rc0) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.8,>=2.7->tensorflow-gpu==2.8.0rc0) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.8,>=2.7->tensorflow-gpu==2.8.0rc0) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.8,>=2.7->tensorflow-gpu==2.8.0rc0) (2023.7.22)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=0.11.15->tensorboard<2.8,>=2.7->tensorflow-gpu==2.8.0rc0) (2.1.3)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.8,>=2.7->tensorflow-gpu==2.8.0rc0) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.8,>=2.7->tensorflow-gpu==2.8.0rc0) (3.2.2)\n","Installing collected packages: tf-estimator-nightly, tensorboard-plugin-wit, keras, tensorboard-data-server, setuptools, keras-preprocessing, google-auth-oauthlib, tensorboard, tensorflow-gpu\n","  Attempting uninstall: keras\n","    Found existing installation: keras 2.13.1\n","    Uninstalling keras-2.13.1:\n","      Successfully uninstalled keras-2.13.1\n","  Attempting uninstall: tensorboard-data-server\n","    Found existing installation: tensorboard-data-server 0.7.1\n","    Uninstalling tensorboard-data-server-0.7.1:\n","      Successfully uninstalled tensorboard-data-server-0.7.1\n","  Attempting uninstall: setuptools\n","    Found existing installation: setuptools 67.7.2\n","    Uninstalling setuptools-67.7.2:\n","      Successfully uninstalled setuptools-67.7.2\n","  Attempting uninstall: google-auth-oauthlib\n","    Found existing installation: google-auth-oauthlib 1.0.0\n","    Uninstalling google-auth-oauthlib-1.0.0:\n","      Successfully uninstalled google-auth-oauthlib-1.0.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.13.0\n","    Uninstalling tensorboard-2.13.0:\n","      Successfully uninstalled tensorboard-2.13.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","ipython 7.34.0 requires jedi>=0.16, which is not installed.\n","arviz 0.15.1 requires setuptools>=60.0.0, but you have setuptools 59.8.0 which is incompatible.\n","cvxpy 1.3.2 requires setuptools>65.5.1, but you have setuptools 59.8.0 which is incompatible.\n","tensorflow 2.13.0 requires keras<2.14,>=2.13.1, but you have keras 2.8.0 which is incompatible.\n","tensorflow 2.13.0 requires tensorboard<2.14,>=2.13, but you have tensorboard 2.7.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed google-auth-oauthlib-0.4.6 keras-2.8.0 keras-preprocessing-1.1.2 setuptools-59.8.0 tensorboard-2.7.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-gpu-2.8.0rc0 tf-estimator-nightly-2.8.0.dev2021122109\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["_distutils_hack","pkg_resources","setuptools"]}}},"metadata":{}}],"source":["!pip install tensorflow-gpu==2.8.0rc0"]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","\n","tf.__version__"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"93gO-JI1zW5Z","executionInfo":{"status":"ok","timestamp":1694406538879,"user_tz":-540,"elapsed":2613,"user":{"displayName":"띵현","userId":"11430659926875687373"}},"outputId":"2008e7ca-1a4d-48b1-be66-c42f0558e283"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.8.0-rc0'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["class  PositionalEncoding(tf.keras.layers.Layer):\n","  def __init__(self, position, d_model):\n","    super(PositionalEncoding, self).__init__()\n","    self.pos_encoding = self.positional_encoding(position, d_model)\n","\n","  def get_angles(self, position, i, d_model):\n","    angles = 1/ tf.pow(10000, (2*(i//2)) / tf.cast(d_model, tf.float32))\n","    return position * angles\n","\n","  def positional_encoding(self, position, d_model):\n","    angle_rads = self.get_angles(\n","        position = tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n","        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n","        d_model=d_model)\n","\n","    #배열의 짝수 인덱스(2i)에는 사인 함수\n","    sines = tf.math.sin(angle_rads[:, 0::2])\n","\n","    #배열의 홀수 인덱스(2i+1)에는 코사인 함수 적용\n","    cosines = tf.math.cos(angle_rads[:, 1::2])\n","\n","    angle_rads = np.zeros(angle_rads.shape)\n","    angle_rads[:, 0::2] = sines\n","    angle_rads[:, 1::2] = cosines\n","    pos_encoding = tf.constant(angle_rads)\n","    pos_encoding = pos_encoding[tf.newaxis, ...]\n","\n","    print(pos_encoding.shape)\n","    return tf.cast(pos_encoding, tf.float32)\n","\n","  def call(self, inputs):\n","    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"],"metadata":{"id":"gqN9w38Mzt4m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def scaled_dot_product_attention(query, key, value, mask):\n","  # query 크기 : (batch_siize, num_heads, query의 문장 길이, d_model/num_heads)\n","  # key 크기 : (batch_siize, num_heads, key의 문장 길이, d_model/num_heads)\n","  # value 크기 : (batch_siize, num_heads, value의 문장 길이, d_model/num_heads)\n","  # paddig_mask : (batch_size, 1, 1, key의 문장 길이)\n","\n","  # Q와 K의 곱, 어텐션 스코어 행렬.\n","  matmul_qk = tf.matmul(query, key, transpose_b = True)\n","  # 스케일링\n","  # qk의 루트값으로 나눠준다.\n","  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n","  logits = matmul_qk / tf.math.sqrt(depth)\n","\n","  # 마스킹, 어텐션 스코어 행렬의 마스킹 할 위치에 매우 작은 음수 값을 넣는다.\n","  # 매우 작은 값이므로 소프트맥스 함수를 지나면 행렬의 해당 위치의 값은 0이 된다.\n","  if mask is not None:\n","    logits += (mask * -1e9)\n","\n","  # 소프트맥스 함수는 마지막 차원인 key의 문장 길이 방향으로 수행된다.\n","  # attention weight : (batch_siize, num_heads, query의 문장 길이, key의 문장 길이)\n","  attention_weights = tf.nn.softmax(logits, axis=-1)\n","\n","  output =  tf.matmul(attention_weights, value)\n","\n","  return output, attention_weights"],"metadata":{"id":"i1aHZiTp3c6X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["np.set_printoptions(suppress=True)\n","temp_k = tf.constant([[10,0,0],\n","                      [0,10,0],\n","                      [0,0,10],\n","                      [0,0,10]], dtype = tf.float32) # (4, 3)\n","\n","temp_v = tf.constant([[1,0],\n","                      [10,0],\n","                      [100,5],\n","                      [1000,6]], dtype = tf.float32) # (4, 2)\n","temp_q = tf.constant([[0,10,0]], dtype = tf.float32)"],"metadata":{"id":"fStewQuk64HH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["temp_out, temp_attn = scaled_dot_product_attention(temp_q, temp_k, temp_v, None)\n","print(temp_attn)\n","print(temp_out)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IAiCyHo_7fnl","executionInfo":{"status":"ok","timestamp":1694406543251,"user_tz":-540,"elapsed":2351,"user":{"displayName":"띵현","userId":"11430659926875687373"}},"outputId":"d09cf5d3-4dc4-45df-8c2a-30b2e8cbbe44"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor([[0. 1. 0. 0.]], shape=(1, 4), dtype=float32)\n","tf.Tensor([[10.  0.]], shape=(1, 2), dtype=float32)\n"]}]},{"cell_type":"code","source":["temp_q = tf.constant([[0,0,10]], dtype = tf.float32)\n","temp_out, temp_attn = scaled_dot_product_attention(temp_q, temp_k, temp_v, None)\n","print(temp_attn)\n","print(temp_out)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iM6InOx18D-Q","executionInfo":{"status":"ok","timestamp":1694406543251,"user_tz":-540,"elapsed":14,"user":{"displayName":"띵현","userId":"11430659926875687373"}},"outputId":"7fde0558-6630-4272-f398-fe2e654ab882"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor([[0.  0.  0.5 0.5]], shape=(1, 4), dtype=float32)\n","tf.Tensor([[550.    5.5]], shape=(1, 2), dtype=float32)\n"]}]},{"cell_type":"code","source":["temp_q = tf.constant([[0,0,10],[0,10,0],[10,10,0]], dtype = tf.float32)\n","temp_out, temp_attn = scaled_dot_product_attention(temp_q, temp_k, temp_v, None)\n","print(temp_attn)\n","print(temp_out)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6scC232-8QvZ","executionInfo":{"status":"ok","timestamp":1694406543251,"user_tz":-540,"elapsed":11,"user":{"displayName":"띵현","userId":"11430659926875687373"}},"outputId":"9783078f-c2e1-43a3-cfe3-a22eb5d22f83"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(\n","[[0.  0.  0.5 0.5]\n"," [0.  1.  0.  0. ]\n"," [0.5 0.5 0.  0. ]], shape=(3, 4), dtype=float32)\n","tf.Tensor(\n","[[550.    5.5]\n"," [ 10.    0. ]\n"," [  5.5   0. ]], shape=(3, 2), dtype=float32)\n"]}]},{"cell_type":"code","source":["class MultiHeadAttention(tf.keras.layers.Layer):\n","\n","  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n","    super(MultiHeadAttention, self).__init__(name=name)\n","    self.num_heads = num_heads\n","    self.d_model = d_model\n","\n","    assert d_model % self.num_heads == 0\n","\n","    # d_model을 num_heads로 나눈 값.\n","    # 논문 기준 : 64\n","    self.depth = d_model // self.num_heads\n","\n","    # WQ, WK, WV에 해당하는 밀집층 정의\n","    self.query_dense = tf.keras.layers.Dense(units=d_model)\n","    self.key_dense = tf.keras.layers.Dense(units=d_model)\n","    self.value_dense = tf.keras.layers.Dense(units=d_model)\n","\n","    # WO에 해당하는 밀집층 정의\n","    self.dense = tf.keras.layers.Dense(units=d_model)\n","\n","  # num_heads 개수만큼 q, k, v를 split하는 함수\n","  def split_heads(self, inputs, batch_size):\n","    inputs = tf.reshape(\n","        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n","    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n","\n","  def call(self, inputs):\n","    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n","        'value'], inputs['mask']\n","    batch_size = tf.shape(query)[0]\n","\n","    # 1. WQ, WK, WV에 해당하는 밀집층 지나기\n","    # q : (batch_size, query의 문장 길이, d_model)\n","    # k : (batch_size, key의 문장 길이, d_model)\n","    # v : (batch_size, value의 문장 길이, d_model)\n","    # 참고) 인코더(k, v)-디코더(q) 어텐션에서는 query 길이와 key, value의 길이는 다를 수 있다.\n","    query = self.query_dense(query)\n","    key = self.key_dense(key)\n","    value = self.value_dense(value)\n","\n","    # 2. 헤드 나누기\n","    # q : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n","    # k : (batch_size, num_heads, key의 문장 길이, d_model/num_heads)\n","    # v : (batch_size, num_heads, value의 문장 길이, d_model/num_heads)\n","    query = self.split_heads(query, batch_size)\n","    key = self.split_heads(key, batch_size)\n","    value = self.split_heads(value, batch_size)\n","\n","    # 3. 스케일드 닷 프로덕트 어텐션. 앞서 구현한 함수 사용.\n","    # (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n","    scaled_attention, _ = scaled_dot_product_attention(query, key, value, mask)\n","    # (batch_size, query의 문장 길이, num_heads, d_model/num_heads)\n","    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n","\n","    # 4. 헤드 연결(concatenate)하기\n","    # (batch_size, query의 문장 길이, d_model)\n","    concat_attention = tf.reshape(scaled_attention,\n","                                  (batch_size, -1, self.d_model))\n","\n","    # 5. WO에 해당하는 밀집층 지나기\n","    # (batch_size, query의 문장 길이, d_model)\n","    outputs = self.dense(concat_attention)\n","\n","    return outputs\n"],"metadata":{"id":"UV-LHrsv8rYE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_padding_mask(x):\n","  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n","  # (batch_size, 1, 1, key의 문장 길이)\n","  return mask[:, tf.newaxis, tf.newaxis, :]\n"],"metadata":{"id":"S2xDyVuX-YmT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(create_padding_mask(tf.constant([[1,21,777,0,0]])))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8fN7hbprGOqq","executionInfo":{"status":"ok","timestamp":1694406543252,"user_tz":-540,"elapsed":9,"user":{"displayName":"띵현","userId":"11430659926875687373"}},"outputId":"943ef5df-e6b4-45de-8c4c-ea7618f17975"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor([[[[0. 0. 0. 1. 1.]]]], shape=(1, 1, 1, 5), dtype=float32)\n"]}]},{"cell_type":"code","source":["def encoder_layer(dff, d_model, num_heads, dropout, name=\"encoder_layer\"):\n","  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n","\n","  # 인코더는 패딩 마스크 사용\n","  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n","\n","  # 멀티-헤드 어텐션 (첫번째 서브층 / 셀프 어텐션)\n","  attention = MultiHeadAttention(\n","      d_model, num_heads, name=\"attention\")({\n","          'query': inputs, 'key': inputs, 'value': inputs, # Q = K = V\n","          'mask': padding_mask # 패딩 마스크 사용\n","      })\n","\n","  # 드롭아웃 + 잔차 연결과 층 정규화\n","  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n","  attention = tf.keras.layers.LayerNormalization(\n","      epsilon=1e-6)(inputs + attention)\n","\n","  # 포지션 와이즈 피드 포워드 신경망 (두번째 서브층)\n","  outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention)\n","  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n","\n","  # 드롭아웃 + 잔차 연결과 층 정규화\n","  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n","  outputs = tf.keras.layers.LayerNormalization(\n","      epsilon=1e-6)(attention + outputs)\n","\n","  return tf.keras.Model(\n","      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n"],"metadata":{"id":"noOWJHMUF0tL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def encoder(vocab_size, num_layers, dff,\n","            d_model, num_heads, dropout,\n","            name=\"encoder\"):\n","  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n","\n","  # 인코더는 패딩 마스크 사용\n","  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n","\n","  # 포지셔널 인코딩 + 드롭아웃\n","  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n","  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n","  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n","  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n","\n","  # 인코더를 num_layers개 쌓기\n","  for i in range(num_layers):\n","    outputs = encoder_layer(dff=dff, d_model=d_model, num_heads=num_heads,\n","        dropout=dropout, name=\"encoder_layer_{}\".format(i),\n","    )([outputs, padding_mask])\n","\n","  return tf.keras.Model(\n","      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n"],"metadata":{"id":"Dn2xAhtyIjQZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 디코더의 첫번째 서브층(sublayer)에서 미래 토큰을 Mask하는 함수\n","def create_look_ahead_mask(x):\n","  seq_len = tf.shape(x)[1]\n","  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n","  padding_mask = create_padding_mask(x) # 패딩 마스크도 포함\n","  return tf.maximum(look_ahead_mask, padding_mask)\n"],"metadata":{"id":"ehrNcu7pKR--"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(create_look_ahead_mask(tf.constant([[1, 2, 0, 4, 5]])))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RH2UbvUZLRB4","executionInfo":{"status":"ok","timestamp":1694406543253,"user_tz":-540,"elapsed":8,"user":{"displayName":"띵현","userId":"11430659926875687373"}},"outputId":"a5b1c091-e7e5-47c8-c192-8fc8ed262c30"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(\n","[[[[0. 1. 1. 1. 1.]\n","   [0. 0. 1. 1. 1.]\n","   [0. 0. 1. 1. 1.]\n","   [0. 0. 1. 0. 1.]\n","   [0. 0. 1. 0. 0.]]]], shape=(1, 1, 5, 5), dtype=float32)\n"]}]},{"cell_type":"code","source":["def decoder_layer(dff, d_model, num_heads, dropout, name=\"decoder_layer\"):\n","  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n","  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n","\n","  # 룩어헤드 마스크(첫번째 서브층)\n","  look_ahead_mask = tf.keras.Input(\n","      shape=(1, None, None), name=\"look_ahead_mask\")\n","\n","  # 패딩 마스크(두번째 서브층)\n","  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n","\n","  # 멀티-헤드 어텐션 (첫번째 서브층 / 마스크드 셀프 어텐션)\n","  attention1 = MultiHeadAttention(\n","      d_model, num_heads, name=\"attention_1\")(inputs={\n","          'query': inputs, 'key': inputs, 'value': inputs, # Q = K = V\n","          'mask': look_ahead_mask # 룩어헤드 마스크\n","      })\n","\n","  # 잔차 연결과 층 정규화\n","  attention1 = tf.keras.layers.LayerNormalization(\n","      epsilon=1e-6)(attention1 + inputs)\n","\n","  # 멀티-헤드 어텐션 (두번째 서브층 / 디코더-인코더 어텐션)\n","  attention2 = MultiHeadAttention(\n","      d_model, num_heads, name=\"attention_2\")(inputs={\n","          'query': attention1, 'key': enc_outputs, 'value': enc_outputs, # Q != K = V\n","          'mask': padding_mask # 패딩 마스크\n","      })\n","\n","  # 드롭아웃 + 잔차 연결과 층 정규화\n","  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n","  attention2 = tf.keras.layers.LayerNormalization(\n","      epsilon=1e-6)(attention2 + attention1)\n","\n","  # 포지션 와이즈 피드 포워드 신경망 (세번째 서브층)\n","  outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention2)\n","  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n","\n","  # 드롭아웃 + 잔차 연결과 층 정규화\n","  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n","  outputs = tf.keras.layers.LayerNormalization(\n","      epsilon=1e-6)(outputs + attention2)\n","\n","  return tf.keras.Model(\n","      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n","      outputs=outputs,\n","      name=name)\n"],"metadata":{"id":"apAuJBmzLXbB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def decoder(vocab_size, num_layers, dff,\n","            d_model, num_heads, dropout,\n","            name='decoder'):\n","  inputs = tf.keras.Input(shape=(None,), name='inputs')\n","  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n","\n","  # 디코더는 룩어헤드 마스크(첫번째 서브층)와 패딩 마스크(두번째 서브층) 둘 다 사용.\n","  look_ahead_mask = tf.keras.Input(\n","      shape=(1, None, None), name='look_ahead_mask')\n","  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n","\n","  # 포지셔널 인코딩 + 드롭아웃\n","  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n","  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n","  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n","  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n","\n","  # 디코더를 num_layers개 쌓기\n","  for i in range(num_layers):\n","    outputs = decoder_layer(dff=dff, d_model=d_model, num_heads=num_heads,\n","        dropout=dropout, name='decoder_layer_{}'.format(i),\n","    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n","\n","  return tf.keras.Model(\n","      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n","      outputs=outputs,\n","      name=name)\n"],"metadata":{"id":"Bkj1vz63R3BS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def transformer(vocab_size, num_layers, dff,\n","                d_model, num_heads, dropout,\n","                name=\"transformer\"):\n","\n","  # 인코더의 입력\n","  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n","\n","  # 디코더의 입력\n","  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n","\n","  # 인코더의 패딩 마스크\n","  enc_padding_mask = tf.keras.layers.Lambda(\n","      create_padding_mask, output_shape=(1, 1, None),\n","      name='enc_padding_mask')(inputs)\n","\n","  # 디코더의 룩어헤드 마스크(첫번째 서브층)\n","  look_ahead_mask = tf.keras.layers.Lambda(\n","      create_look_ahead_mask, output_shape=(1, None, None),\n","      name='look_ahead_mask')(dec_inputs)\n","\n","  # 디코더의 패딩 마스크(두번째 서브층)\n","  dec_padding_mask = tf.keras.layers.Lambda(\n","      create_padding_mask, output_shape=(1, 1, None),\n","      name='dec_padding_mask')(inputs)\n","\n","  # 인코더의 출력은 enc_outputs. 디코더로 전달된다.\n","  enc_outputs = encoder(vocab_size=vocab_size, num_layers=num_layers, dff=dff,\n","      d_model=d_model, num_heads=num_heads, dropout=dropout,\n","  )(inputs=[inputs, enc_padding_mask]) # 인코더의 입력은 입력 문장과 패딩 마스크\n","\n","  # 디코더의 출력은 dec_outputs. 출력층으로 전달된다.\n","  dec_outputs = decoder(vocab_size=vocab_size, num_layers=num_layers, dff=dff,\n","      d_model=d_model, num_heads=num_heads, dropout=dropout,\n","  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n","\n","  # 다음 단어 예측을 위한 출력층\n","  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n","\n","  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)\n"],"metadata":{"id":"RmMna5gDS3hH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def loss_funtion(y_true, y_pred):\n","  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n","\n","  loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True,\n","                                                       reduction=\"none\")(y_true, y_pred)\n","\n","  mask = tf.cast(tf.not_equal(y_true,0), tf.float32)\n","  loss = tf.multiply(loss, mask)\n","\n","  return tf.reduce_mean(loss)"],"metadata":{"id":"gl9_SHXqWCwS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n","\n","  def __init__(self, d_model, warmup_steps=4000):\n","    super(CustomSchedule, self).__init__()\n","    self.d_model = d_model\n","    self.d_model = tf.cast(self.d_model, tf.float32)\n","    self.warmup_steps = warmup_steps\n","\n","  def __call__(self, step):\n","    arg1 = tf.math.rsqrt(step)\n","    arg2 = step * (self.warmup_steps**-1.5)\n","\n","    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n"],"metadata":{"id":"UjA2aBp7XV4O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import urllib.request\n","import tensorflow_datasets as tfds\n","import tensorflow as tf\n","import time\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import re"],"metadata":{"id":"u7xKQ4erH5Lp","executionInfo":{"status":"ok","timestamp":1695636191856,"user_tz":-540,"elapsed":4210,"user":{"displayName":"띵현","userId":"11430659926875687373"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["urllib.request.urlretrieve(\"https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData.csv\", filename=\"ChatBotData.csv\")\n","\n","train_data = pd.read_csv('ChatBotData.csv')\n","train_data.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"62M6WC-rIpR9","executionInfo":{"status":"ok","timestamp":1695636194112,"user_tz":-540,"elapsed":492,"user":{"displayName":"띵현","userId":"11430659926875687373"}},"outputId":"24189dd1-ed38-4363-ec00-a873fec0685d"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                 Q            A  label\n","0           12시 땡!   하루가 또 가네요.      0\n","1      1지망 학교 떨어졌어    위로해 드립니다.      0\n","2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n","3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n","4          PPL 심하네   눈살이 찌푸려지죠.      0"],"text/html":["\n","  <div id=\"df-5c8ab52c-c90d-4926-b5d8-2a9302466032\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Q</th>\n","      <th>A</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>12시 땡!</td>\n","      <td>하루가 또 가네요.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1지망 학교 떨어졌어</td>\n","      <td>위로해 드립니다.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3박4일 놀러가고 싶다</td>\n","      <td>여행은 언제나 좋죠.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3박4일 정도 놀러가고 싶다</td>\n","      <td>여행은 언제나 좋죠.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>PPL 심하네</td>\n","      <td>눈살이 찌푸려지죠.</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5c8ab52c-c90d-4926-b5d8-2a9302466032')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-5c8ab52c-c90d-4926-b5d8-2a9302466032 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-5c8ab52c-c90d-4926-b5d8-2a9302466032');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-8962b4f3-a9ae-41ab-8ace-1ed19d9e6f8d\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8962b4f3-a9ae-41ab-8ace-1ed19d9e6f8d')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-8962b4f3-a9ae-41ab-8ace-1ed19d9e6f8d button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["print('챗봇 샘플의 개수 :', len(train_data))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yWk2SjTTIpIm","executionInfo":{"status":"ok","timestamp":1694406544761,"user_tz":-540,"elapsed":10,"user":{"displayName":"띵현","userId":"11430659926875687373"}},"outputId":"e75f32cd-c4ba-4b44-ed1f-ad49cf211f07"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["챗봇 샘플의 개수 : 11823\n"]}]},{"cell_type":"code","source":["print(train_data.isnull().sum())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DrYarh2EKotl","executionInfo":{"status":"ok","timestamp":1694406544761,"user_tz":-540,"elapsed":7,"user":{"displayName":"띵현","userId":"11430659926875687373"}},"outputId":"c37d873e-ba08-4758-e17d-5153cc36f2cc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Q        0\n","A        0\n","label    0\n","dtype: int64\n"]}]},{"cell_type":"code","source":["questions = []\n","for sentence in train_data['Q']:\n","    # 구두점에 대해서 띄어쓰기\n","    # ex) 12시 땡! -> 12시 땡 !\n","    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence) # re.sub(pattern, repl, string)\n","                                                      # pattern : 찾을 패턴을 지정하는 문자열\n","                                                      # repl : 찾은 패턴을 교체할 문자열 \" \\1\" : 첫번째 소괄호 적용\n","                                                      # string : 패턴 검색 및 교체를 수행할 원본 문자열\n","    sentence = sentence.strip() # 문자열의 앞뒤에 있는 공백을 제거\n","    questions.append(sentence)\n"],"metadata":{"id":"06HdIvtLK5id"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["answers = []\n","for sentence in train_data['A']:\n","    # 구두점에 대해서 띄어쓰기\n","    # ex) 12시 땡! -> 12시 땡 !\n","    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n","    sentence = sentence.strip()\n","    answers.append(sentence)\n"],"metadata":{"id":"p1ySNrh_MR_p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(questions[:5])\n","print(answers[:5])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z63ES4X8MXlr","executionInfo":{"status":"ok","timestamp":1694406545360,"user_tz":-540,"elapsed":3,"user":{"displayName":"띵현","userId":"11430659926875687373"}},"outputId":"71161cbb-bade-4253-f8ee-5a7e9b0e4fc4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['12시 땡 !', '1지망 학교 떨어졌어', '3박4일 놀러가고 싶다', '3박4일 정도 놀러가고 싶다', 'PPL 심하네']\n","['하루가 또 가네요 .', '위로해 드립니다 .', '여행은 언제나 좋죠 .', '여행은 언제나 좋죠 .', '눈살이 찌푸려지죠 .']\n"]}]},{"cell_type":"code","source":["# 서브워드텍스트인코더를 사용하여 질문, 답변 데이터로부터 단어 집합(Vocabulary) 생성\n","tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n","    questions + answers, target_vocab_size=2**13) # 8192개"],"metadata":{"id":"jfMYFRozMhKM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","*   **tfds.deprecated.text.SubwordTextEncoder** :  텍스트를 서브워드 단위로 인코딩하고 디코딩하는 데 사용되는 클래스\n","*   **build_from_corpus** : 주어진 텍스트 데이터에서 서브워드 텍스트 인코더를 학습시키는 메서드\n","\n"],"metadata":{"id":"8d-6b0w9NZHf"}},{"cell_type":"code","source":["tokenizer.vocab_size"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oDNdRN9cO3-2","executionInfo":{"status":"ok","timestamp":1694406556940,"user_tz":-540,"elapsed":11,"user":{"displayName":"띵현","userId":"11430659926875687373"}},"outputId":"7d50f3d1-0128-4c95-b192-7f5cbf227ba0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["8178"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["# 시작 토큰과 종료 토큰에 대한 정수 부여.\n","START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n","\n","# 시작 토큰과 종료 토큰을 고려하여 단어 집합의 크기를 + 2\n","VOCAB_SIZE = tokenizer.vocab_size + 2\n"],"metadata":{"id":"HxefoWsXMtk3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('시작 토큰 번호 :',START_TOKEN)\n","print('종료 토큰 번호 :',END_TOKEN)\n","print('단어 집합의 크기 :',VOCAB_SIZE)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HriPX8ycPMdV","executionInfo":{"status":"ok","timestamp":1694406556941,"user_tz":-540,"elapsed":11,"user":{"displayName":"띵현","userId":"11430659926875687373"}},"outputId":"d2f3cc08-1f34-4eed-eff2-37e282fd294c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["시작 토큰 번호 : [8178]\n","종료 토큰 번호 : [8179]\n","단어 집합의 크기 : 8180\n"]}]},{"cell_type":"code","source":["# 서브워드텍스트인코더 토크나이저의 .encode()를 사용하여 텍스트 시퀀스를 정수 시퀀스로 변환.\n","print('임의의 질문 샘플을 정수 인코딩 : {}'.format(tokenizer.encode(questions[20])))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C1e3ADcbPnMx","executionInfo":{"status":"ok","timestamp":1694406556941,"user_tz":-540,"elapsed":9,"user":{"displayName":"띵현","userId":"11430659926875687373"}},"outputId":"f7df8f64-dae6-4fb2-8661-e3e7d80e120e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["임의의 질문 샘플을 정수 인코딩 : [5766, 611, 3509, 141, 685, 3747, 849]\n"]}]},{"cell_type":"code","source":["# 서브워드텍스트인코더 토크나이저의 .encode()와 .decode() 테스트해보기\n","# 임의의 입력 문장을 sample_string에 저장\n","sample_string = questions[20]\n","print(\"원본 sample_string :\" ,sample_string)\n","# encode() : 텍스트 시퀀스 --> 정수 시퀀스\n","tokenized_string = tokenizer.encode(sample_string)\n","print ('정수 인코딩 후의 문장 {}'.format(tokenized_string))\n","\n","# decode() : 정수 시퀀스 --> 텍스트 시퀀스\n","original_string = tokenizer.decode(tokenized_string)\n","print ('기존 문장: {}'.format(original_string))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fx7KpK95QC1_","executionInfo":{"status":"ok","timestamp":1694406556941,"user_tz":-540,"elapsed":7,"user":{"displayName":"띵현","userId":"11430659926875687373"}},"outputId":"868b872e-15c1-47f0-aea8-8f43cc8a5dfd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["원본 sample_string : 가스비 비싼데 감기 걸리겠어\n","정수 인코딩 후의 문장 [5766, 611, 3509, 141, 685, 3747, 849]\n","기존 문장: 가스비 비싼데 감기 걸리겠어\n"]}]},{"cell_type":"code","source":["# 각 정수는 각 단어와 어떻게 mapping되는지 병렬로 출력\n","# 서브워드텍스트인코더는 의미있는 단위의 서브워드로 토크나이징한다. 띄어쓰기 단위 X 형태소 분석 단위 X\n","for ts in tokenized_string:\n","  print ('{} ----> {}'.format(ts, tokenizer.decode([ts])))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lu_9fk_PQeyx","executionInfo":{"status":"ok","timestamp":1694406556941,"user_tz":-540,"elapsed":6,"user":{"displayName":"띵현","userId":"11430659926875687373"}},"outputId":"a36dc58b-4e61-4daf-cea4-b5a5971d7e33"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["5766 ----> 가스\n","611 ----> 비 \n","3509 ----> 비싼\n","141 ----> 데 \n","685 ----> 감기 \n","3747 ----> 걸리\n","849 ----> 겠어\n"]}]},{"cell_type":"code","source":["# 최대 길이를 40으로 정의\n","MAX_LENGTH = 40\n","\n","# 토큰화 / 정수 인코딩 / 시작 토큰과 종료 토큰 추가 / 패딩\n","def tokenize_and_filter(inputs, outputs):\n","  tokenized_inputs, tokenized_outputs = [], []\n","\n","  for (sentence1, sentence2) in zip(inputs, outputs):\n","    # encode(토큰화 + 정수 인코딩), 시작 토큰과 종료 토큰 추가\n","    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n","    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n","\n","    tokenized_inputs.append(sentence1)\n","    tokenized_outputs.append(sentence2)\n","\n","  # 패딩\n","  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n","      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n","  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n","      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n","\n","  return tokenized_inputs, tokenized_outputs\n"],"metadata":{"id":"c5SXqqGsSuCC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["questions, answers = tokenize_and_filter(questions, answers)"],"metadata":{"id":"X_pe3AeqTws4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["questions\n","answers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i8tR7rI1T8aA","executionInfo":{"status":"ok","timestamp":1694406557708,"user_tz":-540,"elapsed":11,"user":{"displayName":"띵현","userId":"11430659926875687373"}},"outputId":"2e2ac635-9de3-407a-ab5a-716845245951"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[8178, 3844,   74, ...,    0,    0,    0],\n","       [8178, 1830, 5502, ...,    0,    0,    0],\n","       [8178, 3400,  777, ...,    0,    0,    0],\n","       ...,\n","       [8178, 5211,  287, ...,    0,    0,    0],\n","       [8178,   13, 3201, ...,    0,    0,    0],\n","       [8178,  221,  555, ...,    0,    0,    0]], dtype=int32)"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","source":["print('질문 데이터의 크기(shape) :', questions.shape) # 문장의 길이가 모두 40으로 변경됨\n","print('답변 데이터의 크기(shape) :', answers.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jdVQTOkUUO2L","executionInfo":{"status":"ok","timestamp":1694406557708,"user_tz":-540,"elapsed":10,"user":{"displayName":"띵현","userId":"11430659926875687373"}},"outputId":"bef8677b-c816-438c-ffe4-e4ae37cd724f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["질문 데이터의 크기(shape) : (11823, 40)\n","답변 데이터의 크기(shape) : (11823, 40)\n"]}]},{"cell_type":"code","source":["type(questions)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FNGJBTgUUrWl","executionInfo":{"status":"ok","timestamp":1694406557708,"user_tz":-540,"elapsed":8,"user":{"displayName":"띵현","userId":"11430659926875687373"}},"outputId":"6fd7f8de-0b0e-4ef4-c94d-67c107b940bf"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["numpy.ndarray"]},"metadata":{},"execution_count":39}]},{"cell_type":"code","source":["print(questions[0])\n","print(answers[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ixOpMoZkUeYS","executionInfo":{"status":"ok","timestamp":1694406557708,"user_tz":-540,"elapsed":7,"user":{"displayName":"띵현","userId":"11430659926875687373"}},"outputId":"ac10f0a3-ec62-42b5-b05b-a886d12a4a4a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[8178 7915 4207 3060   41 8179    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0]\n","[8178 3844   74 7894    1 8179    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0]\n"]}]},{"cell_type":"markdown","source":["\n","\n","*   **tf.data.Dataset.from_tensor_slices** : 텐서를 개별 요소로 \"슬라이스(slice)\"하는 것입니다. 텐서를 슬라이스하면, 각 요소가 데이터셋의 한 아이템(item)이 됩니다.\n","\n","\n"],"metadata":{"id":"EtVyTS6cV18R"}},{"cell_type":"markdown","source":["**cache()**: 데이터를 캐시에 저장하여 빠른 읽기를 가능하게 합니다.\n","\n","**shuffle(BUFFER_SIZE)**: 데이터셋을 버퍼 크기를 기준으로 무작위로 섞습니다.\n","\n","**batch(BATCH_SIZE)**: 데이터셋을 배치 크기에 따라 묶습니다.\n","\n","**prefetch(tf.data.experimental.AUTOTUNE)**: 학습 도중 데이터 로딩 시간을 단축하기 위해 프리페칭을 활용하여 학습 속도를 향상시킵니다. AUTOTUNE은 텐서플로우가 실행 환경을 보고 적절한 수의 배치를 자동으로 프리페치하도록 합니다."],"metadata":{"id":"BtZKp2afWfqI"}},{"cell_type":"markdown","source":["####**프리페치**를 사용하면, 훈련 알고리즘이 한 배치의 데이터를 처리하는 동안, CPU는 여러 배치의 데이터를 미리 준비(또는 \"프리페치\")할 수 있습니다. 이렇게 하면 GPU는 다음 배치의 데이터를 기다리는 시간 없이 연속적으로 작업을 수행할 수 있습니다, 즉, GPU의 유휴 시간을 줄여 훈련 속도를 향상시킬 수 있습니다."],"metadata":{"id":"5aAjrzdzXFDi"}},{"cell_type":"code","source":["# 텐서플로우 dataset을 이용하여 셔플(shuffle)을 수행하되, 배치 크기로 데이터를 묶는다.\n","# 또한 이 과정에서 교사 강요(teacher forcing)을 사용하기 위해서 디코더의 입력과 실제값 시퀀스를 구성한다.\n","BATCH_SIZE = 64\n","BUFFER_SIZE = 20000\n","\n","# 디코더의 실제값 시퀀스에서는 시작 토큰을 제거해야 한다.\n","dataset = tf.data.Dataset.from_tensor_slices((\n","    {\n","        'inputs': questions,\n","        'dec_inputs': answers[:, :-1] # 디코더의 입력. 마지막 패딩 토큰이 제거된다.\n","    },\n","    {\n","        'outputs': answers[:, 1:]  # 맨 처음 토큰이 제거된다. 다시 말해 시작 토큰이 제거된다.\n","    },\n","))\n","\n","dataset = dataset.cache()\n","dataset = dataset.shuffle(BUFFER_SIZE)\n","dataset = dataset.batch(BATCH_SIZE)\n","dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n"],"metadata":{"id":"60dNp5WaUnRI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 임의의 샘플에 대해서 [:, :-1]과 [:, 1:]이 어떤 의미를 가지는지 테스트해본다.\n","print(answers[0]) # 기존 샘플\n","print(answers[:1][:, :-1]) # 마지막 패딩 토큰 제거하면서 길이가 39가 된다.\n","print(answers[:1][:, 1:]) # 맨 처음 토큰이 제거된다. 다시 말해 시작 토큰이 제거된다. 길이는 역시 39가 된다.\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"evukQpuGXNeO","executionInfo":{"status":"ok","timestamp":1694406557709,"user_tz":-540,"elapsed":7,"user":{"displayName":"띵현","userId":"11430659926875687373"}},"outputId":"546ca8be-d58f-4213-a2a9-9c79d0e638d8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[8178 3844   74 7894    1 8179    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0]\n","[[8178 3844   74 7894    1 8179    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0]]\n","[[3844   74 7894    1 8179    0    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0]]\n"]}]},{"cell_type":"markdown","source":["\n","\n","*   **tf.keras.backend.clear_session()** : TensorFlow의 백엔드 세션을 초기화합니다. 이렇게 하면 이전에 생성된 모델이나 레이어의 잔여 트레이스를 제거하여 새로운 모델을 깨끗한 상태에서 시작\n","\n","*   **D_MODEL**: 모델의 임베딩 레이어와 각 트랜스포머 레이어의 출력 차원 수를 정의합니다. 여기서는 각 단어 벡터의 차원을 256으로 설정하였습니다.\n","\n","\n","*   **NUM_LAYERS** : 트랜스포머 아키텍처에서 인코더와 디코더 각각에 있는 레이어(층)의 수를 지정하는 하이퍼파라미터입니다.\n","\n","*   **멀티 헤드 어텐션 (Multi-Head Attention)** :\n","멀티 헤드 어텐션은 기본적으로 어텐션 메커니즘을 여러 번 병렬로 수행하는 것입니다. 어텐션 메커니즘은 입력 시퀀스의 각 단어에 대해 다른 단어들과의 관계를 평가하고, 이 정보를 사용하여 각 단어의 새로운 표현을 생성합니다.\n","\n","    예를 들어, \"나는 밥을 먹는다\"라는 문장에서 \"먹는다\"라는 단어는 \"밥\"이라는 단어와 더 강한 관계를 가질 것입니다. 어텐션 메커니즘은 이러한 관계를 학습하여 단어의 새로운 표현을 생성합니다.\n","\n","    헤드 (Head)\n","    멀티 헤드 어텐션에서 \"헤드\"란 병렬로 수행되는 각각의 어텐션 메커니즘을 의미합니다. 즉, \"헤드\"는 독립적으로 작동하는 어텐션 계산 유닛입니다.\n","\n","    NUM_HEADS\n","    여기서 NUM_HEADS는 멀티 헤드 어텐션을 수행할 때 사용할 헤드의 수를 지정하는 하이퍼파라미터입니다. NUM_HEADS가 8이라는 것은, 우리가 8개의 서로 다른 어텐션 계산 유닛을 병렬로 사용하여 입력 데이터에 어텐션을 적용한다는 것을 의미합니다.\n","\n","    각 헤드는 동일한 입력 데이터에 대해 작동하지만, 서로 다른 가중치 세트를 사용하여 어텐션을 계산합니다. 이렇게 함으로써 모델은 동시에 여러 다른 표현 공간에서 데이터의 특징을 학습할 수 있습니다. 결과적으로, 각 헤드는 입력 데이터의 다른 \"관점\"을 얻게 됩니다, 그리고 이러한 \"관점\"들은 후속 레이어에서 함께 사용되어 더 복잡하고 풍부한 표현을 형성합니다.\n","\n","\n","*   **DFF 피드포워드 신경망(Feedforward Neural Network, FFNN)** : 내부의 은닉층의 크기를 지정하는 하이퍼파라미터입니다. 트랜스포머 모델 내에서 FFNN은 어텐션 계층 다음에 위치하며, 각 어텐션 계층의 출력을 처리하여 다음 레이어 또는 최종 출력에 대한 입력을 생성\n","\n","*   **DROPOUT** : 모델의 드롭아웃 비율로, 과적합을 방지하기 위해 트레이닝 도중 무작위로 뉴런을 끄는 비율을 설정합니다. 여기서는 10%의 뉴런을 무작위로 끕니다.\n","\n","\n","\n"],"metadata":{"id":"22b8tvPnZOMs"}},{"cell_type":"code","source":["tf.keras.backend.clear_session()\n","\n","# 하이퍼파라미터\n","D_MODEL = 256  # 차원벡터 256개로 나눔\n","NUM_LAYERS = 2 # 인코더 디코더 각각 층이 2개인 레이어\n","NUM_HEADS = 8 #\n","DFF = 512\n","DROPOUT = 0.1\n","\n","model = transformer(\n","    vocab_size=VOCAB_SIZE,\n","    num_layers=NUM_LAYERS,\n","    dff=DFF,\n","    d_model=D_MODEL,\n","    num_heads=NUM_HEADS,\n","    dropout=DROPOUT)\n","# (배치크기, 시퀀스 길이, 임베딩 차원)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fXLQZp-7XWfm","executionInfo":{"status":"ok","timestamp":1694406561403,"user_tz":-540,"elapsed":3699,"user":{"displayName":"띵현","userId":"11430659926875687373"}},"outputId":"4694865d-f7b8-412b-997d-050543a197ae"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(1, 8180, 256)\n","(1, 8180, 256)\n"]}]},{"cell_type":"markdown","source":["\n","\n","*   **tf.keras.losses.SparseCategoricalCrossentropy** : 실제 값(y_true)과 예측 값(y_pred) 사이의 차이를 측정하는 데 사용됩니다. 여기서 \"sparse\"라는 용어는 실제 레이블이 정수 형태로 제공된다는 것을 의미하며, \"categorical\"은 레이블이 여러 클래스 중 하나에 속한다는 것을 나타냅니다.\n","\n","*   **from_logits=True** : 예측 값(y_pred)이 로짓(scale) 형태로 제공되었는지 아니면 확률 형태로 제공되었는지를 나타냅니다. from_logits=True로 설정하면, 함수는 입력 값이 로짓이라고 가정하고 내부적으로 소프트맥스(softmax) 함수를 적용하여 확률로 변환한 후, 크로스 엔트로피 손실을 계산합니다.\n","\n"],"metadata":{"id":"-PjHhUoF3NBD"}},{"cell_type":"code","source":["def loss_function(y_true, y_pred):\n","  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1)) # 배치 크기는 그대로 시퀀스 크기는 1줄임\n","\n","  loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True,\n","                                                       reduction=\"none\")(y_true, y_pred)\n","\n","  mask = tf.cast(tf.not_equal(y_true,0), tf.float32)\n","  loss = tf.multiply(loss, mask)\n","\n","  return tf.reduce_mean(loss)"],"metadata":{"id":"P2t8GoLUd-EG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["learning_rate = CustomSchedule(D_MODEL)\n","\n","optimizer = tf.keras.optimizers.Adam(\n","    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n","\n","def accuracy(y_true, y_pred):\n","  # 레이블의 크기는 (batch_size, MAX_LENGTH - 1)\n","  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n","  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n","\n","model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n"],"metadata":{"id":"AsLl0leQc4II"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ji0D4F5U1RxZ","executionInfo":{"status":"ok","timestamp":1694406569788,"user_tz":-540,"elapsed":8413,"user":{"displayName":"띵현","userId":"11430659926875687373"}},"outputId":"9f962032-43d0-4a4c-e70b-01b4a8bf5a09"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.33.1-py3-none-any.whl (7.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n","Collecting huggingface-hub<1.0,>=0.15.1 (from transformers)\n","  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m119.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n","  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n","Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.16.4 safetensors-0.3.3 tokenizers-0.13.3 transformers-4.33.1\n"]}]},{"cell_type":"code","source":["EPOCHS = 25\n","model.fit(dataset, epochs=EPOCHS)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MGz3CSimerRI","executionInfo":{"status":"ok","timestamp":1694406823589,"user_tz":-540,"elapsed":253807,"user":{"displayName":"띵현","userId":"11430659926875687373"}},"outputId":"00a9d5de-b09b-4680-d3d3-d6909cd0d303"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/25\n","185/185 [==============================] - 16s 53ms/step - loss: 1.4568 - accuracy: 0.0322\n","Epoch 2/25\n","185/185 [==============================] - 10s 52ms/step - loss: 1.1789 - accuracy: 0.0496\n","Epoch 3/25\n","185/185 [==============================] - 10s 52ms/step - loss: 1.0039 - accuracy: 0.0505\n","Epoch 4/25\n","185/185 [==============================] - 10s 52ms/step - loss: 0.9281 - accuracy: 0.0542\n","Epoch 5/25\n","185/185 [==============================] - 10s 53ms/step - loss: 0.8711 - accuracy: 0.0574\n","Epoch 6/25\n","185/185 [==============================] - 10s 53ms/step - loss: 0.8118 - accuracy: 0.0616\n","Epoch 7/25\n","185/185 [==============================] - 10s 53ms/step - loss: 0.7467 - accuracy: 0.0677\n","Epoch 8/25\n","185/185 [==============================] - 10s 53ms/step - loss: 0.6731 - accuracy: 0.0754\n","Epoch 9/25\n","185/185 [==============================] - 10s 54ms/step - loss: 0.5948 - accuracy: 0.0840\n","Epoch 10/25\n","185/185 [==============================] - 10s 55ms/step - loss: 0.5117 - accuracy: 0.0936\n","Epoch 11/25\n","185/185 [==============================] - 10s 54ms/step - loss: 0.4282 - accuracy: 0.1038\n","Epoch 12/25\n","185/185 [==============================] - 10s 54ms/step - loss: 0.3473 - accuracy: 0.1147\n","Epoch 13/25\n","185/185 [==============================] - 10s 54ms/step - loss: 0.2722 - accuracy: 0.1257\n","Epoch 14/25\n","185/185 [==============================] - 10s 54ms/step - loss: 0.2064 - accuracy: 0.1361\n","Epoch 15/25\n","185/185 [==============================] - 10s 54ms/step - loss: 0.1520 - accuracy: 0.1454\n","Epoch 16/25\n","185/185 [==============================] - 10s 53ms/step - loss: 0.1094 - accuracy: 0.1530\n","Epoch 17/25\n","185/185 [==============================] - 10s 54ms/step - loss: 0.0797 - accuracy: 0.1586\n","Epoch 18/25\n","185/185 [==============================] - 10s 54ms/step - loss: 0.0615 - accuracy: 0.1619\n","Epoch 19/25\n","185/185 [==============================] - 10s 54ms/step - loss: 0.0511 - accuracy: 0.1636\n","Epoch 20/25\n","185/185 [==============================] - 10s 54ms/step - loss: 0.0452 - accuracy: 0.1644\n","Epoch 21/25\n","185/185 [==============================] - 10s 54ms/step - loss: 0.0428 - accuracy: 0.1649\n","Epoch 22/25\n","185/185 [==============================] - 10s 54ms/step - loss: 0.0403 - accuracy: 0.1653\n","Epoch 23/25\n","185/185 [==============================] - 10s 54ms/step - loss: 0.0367 - accuracy: 0.1660\n","Epoch 24/25\n","185/185 [==============================] - 10s 54ms/step - loss: 0.0314 - accuracy: 0.1674\n","Epoch 25/25\n","185/185 [==============================] - 10s 54ms/step - loss: 0.0262 - accuracy: 0.1685\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7d967790f2b0>"]},"metadata":{},"execution_count":47}]},{"cell_type":"code","source":["def preprocess_sentence(sentence):\n","  # 단어와 구두점 사이에 공백 추가.\n","  # ex) 12시 땡! -> 12시 땡 !\n","  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n","  sentence = sentence.strip()\n","  return sentence"],"metadata":{"id":"dwQVzh0biIQ6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def evaluate(sentence):\n","  # 입력 문장에 대한 전처리\n","  sentence = preprocess_sentence(sentence)\n","\n","  # 입력 문장에 시작 토큰과 종료 토큰을 추가\n","  sentence = tf.expand_dims(\n","      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n","\n","  output = tf.expand_dims(START_TOKEN, 0)\n","\n","  # 디코더의 예측 시작\n","  for i in range(MAX_LENGTH):\n","    predictions = model(inputs=[sentence, output], training=False)\n","\n","    # 현재 시점의 예측 단어를 받아온다.\n","    predictions = predictions[:, -1:, :]\n","    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n","\n","    # 만약 현재 시점의 예측 단어가 종료 토큰이라면 예측을 중단\n","    if tf.equal(predicted_id, END_TOKEN[0]):\n","      break\n","\n","    # 현재 시점의 예측 단어를 output(출력)에 연결한다.\n","    # output은 for문의 다음 루프에서 디코더의 입력이 된다.\n","    output = tf.concat([output, predicted_id], axis=-1)\n","\n","  # 단어 예측이 모두 끝났다면 output을 리턴.\n","  return tf.squeeze(output, axis=0)"],"metadata":{"id":"sUJkAfiriLJ9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install gtts\n","!pip install playsound"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qff5wnh0rbOW","executionInfo":{"status":"ok","timestamp":1694406833292,"user_tz":-540,"elapsed":9707,"user":{"displayName":"띵현","userId":"11430659926875687373"}},"outputId":"0e897920-09a9-49a4-f79b-0b42d47de328"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting gtts\n","  Downloading gTTS-2.3.2-py3-none-any.whl (28 kB)\n","Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from gtts) (2.31.0)\n","Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.10/dist-packages (from gtts) (8.1.7)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (2023.7.22)\n","Installing collected packages: gtts\n","Successfully installed gtts-2.3.2\n","Collecting playsound\n","  Downloading playsound-1.3.0.tar.gz (7.7 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: playsound\n","  Building wheel for playsound (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for playsound: filename=playsound-1.3.0-py3-none-any.whl size=7036 sha256=a53893870a35ab5df7bcf0b658919ef9eb1049caf740aed98ed2bf287a88b5be\n","  Stored in directory: /root/.cache/pip/wheels/90/89/ed/2d643f4226fc8c7c9156fc28abd8051e2d2c0de37ae51ac45c\n","Successfully built playsound\n","Installing collected packages: playsound\n","Successfully installed playsound-1.3.0\n"]}]},{"cell_type":"code","source":["from gtts import gTTS\n","from IPython.display import Audio\n","from tensorflow import keras"],"metadata":{"id":"YRV0Aj63rco9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def predict(sentence):\n","  prediction = evaluate(sentence)\n","\n","  # prediction == 디코더가 리턴한 챗봇의 대답에 해당하는 정수 시퀀스\n","  # tokenizer.decode()를 통해 정수 시퀀스를 문자열로 디코딩.\n","  predicted_sentence = tokenizer.decode(\n","      [i for i in prediction if i < tokenizer.vocab_size])\n","\n","  print('Input: {}'.format(sentence))\n","  print('Output: {}'.format(predicted_sentence))\n","  tts = gTTS(\n","    text = predicted_sentence,\n","    lang =\"ko\", slow=False\n","    )\n","  tts.save(\"./chatbot_answer.mp3\")\n","  audio_path = \"./chatbot_answer.mp3\"\n","  chat_answer = Audio(audio_path)\n","\n","  return Audio(audio_path)\n"],"metadata":{"id":"pz9_DYrmiN2p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predict(\"영화 볼래?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":110},"id":"NQXdPVONiP_c","executionInfo":{"status":"ok","timestamp":1694406834073,"user_tz":-540,"elapsed":784,"user":{"displayName":"띵현","userId":"11430659926875687373"}},"outputId":"ee907e05-9e0d-4fc1-b33e-8d9a9dfb9165"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Input: 영화 볼래?\n","Output: 최신 영화가 좋을 것 같아요 .\n"]},{"output_type":"execute_result","data":{"text/plain":["<IPython.lib.display.Audio object>"],"text/html":["\n","                <audio  controls=\"controls\" >\n","                    <source src=\"data:audio/mpeg;base64,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\" type=\"audio/mpeg\" />\n","                    Your browser does not support the audio element.\n","                </audio>\n","              "]},"metadata":{},"execution_count":53}]},{"cell_type":"code","source":["predict(\"나 너무 우울해\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":110},"id":"_ysv4Lvcy2qt","executionInfo":{"status":"ok","timestamp":1694406834824,"user_tz":-540,"elapsed":754,"user":{"displayName":"띵현","userId":"11430659926875687373"}},"outputId":"3a196fd3-0476-4f9a-cfd5-2909d33375c1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Input: 나 너무 우울해\n","Output: 우울한 생각들을 멈추세요 .\n"]},{"output_type":"execute_result","data":{"text/plain":["<IPython.lib.display.Audio object>"],"text/html":["\n","                <audio  controls=\"controls\" >\n","                    <source src=\"data:audio/mpeg;base64,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\" type=\"audio/mpeg\" />\n","                    Your browser does not support the audio element.\n","                </audio>\n","              "]},"metadata":{},"execution_count":54}]},{"cell_type":"code","source":["# 모델의 가중치를 저장합니다.\n","model.save_weights('./transformer_weights.h5')"],"metadata":{"id":"RG6vQnHMtFkD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["new_model = transformer(\n","    vocab_size=VOCAB_SIZE,\n","    num_layers=NUM_LAYERS,\n","    dff=DFF,\n","    d_model=D_MODEL,\n","    num_heads=NUM_HEADS,\n","    dropout=DROPOUT)\n","\n","\n","new_model.load_weights('./transformer_weights.h5')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nh9ViiZx24K7","executionInfo":{"status":"ok","timestamp":1694406837312,"user_tz":-540,"elapsed":2495,"user":{"displayName":"띵현","userId":"11430659926875687373"}},"outputId":"da1d0083-100f-4cd8-da1a-c5679b90671e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(1, 8180, 256)\n","(1, 8180, 256)\n"]}]},{"cell_type":"code","source":["new_model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"],"metadata":{"id":"e181CXyL3Fo0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["EPOCHS = 30\n","new_model.fit(dataset, epochs=EPOCHS)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SUrDtQFD3OOe","executionInfo":{"status":"ok","timestamp":1694407143296,"user_tz":-540,"elapsed":305991,"user":{"displayName":"띵현","userId":"11430659926875687373"}},"outputId":"0f637f62-a5ff-4eb0-89c7-137feb72468d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","185/185 [==============================] - 16s 55ms/step - loss: 0.0630 - accuracy: 0.1610\n","Epoch 2/30\n","185/185 [==============================] - 10s 54ms/step - loss: 0.0268 - accuracy: 0.1691\n","Epoch 3/30\n","185/185 [==============================] - 10s 55ms/step - loss: 0.0212 - accuracy: 0.1704\n","Epoch 4/30\n","185/185 [==============================] - 10s 55ms/step - loss: 0.0186 - accuracy: 0.1707\n","Epoch 5/30\n","185/185 [==============================] - 10s 54ms/step - loss: 0.0169 - accuracy: 0.1711\n","Epoch 6/30\n","185/185 [==============================] - 10s 54ms/step - loss: 0.0153 - accuracy: 0.1714\n","Epoch 7/30\n","185/185 [==============================] - 10s 54ms/step - loss: 0.0138 - accuracy: 0.1718\n","Epoch 8/30\n","185/185 [==============================] - 10s 54ms/step - loss: 0.0133 - accuracy: 0.1719\n","Epoch 9/30\n","185/185 [==============================] - 10s 54ms/step - loss: 0.0123 - accuracy: 0.1722\n","Epoch 10/30\n","185/185 [==============================] - 10s 54ms/step - loss: 0.0114 - accuracy: 0.1724\n","Epoch 11/30\n","185/185 [==============================] - 10s 54ms/step - loss: 0.0112 - accuracy: 0.1725\n","Epoch 12/30\n","185/185 [==============================] - 10s 54ms/step - loss: 0.0094 - accuracy: 0.1729\n","Epoch 13/30\n","185/185 [==============================] - 10s 54ms/step - loss: 0.0098 - accuracy: 0.1728\n","Epoch 14/30\n","185/185 [==============================] - 10s 54ms/step - loss: 0.0090 - accuracy: 0.1730\n","Epoch 15/30\n","185/185 [==============================] - 10s 54ms/step - loss: 0.0084 - accuracy: 0.1731\n","Epoch 16/30\n","185/185 [==============================] - 10s 54ms/step - loss: 0.0083 - accuracy: 0.1732\n","Epoch 17/30\n","185/185 [==============================] - 10s 54ms/step - loss: 0.0077 - accuracy: 0.1732\n","Epoch 18/30\n","185/185 [==============================] - 10s 54ms/step - loss: 0.0077 - accuracy: 0.1734\n","Epoch 19/30\n","185/185 [==============================] - 10s 54ms/step - loss: 0.0075 - accuracy: 0.1733\n","Epoch 20/30\n","185/185 [==============================] - 10s 54ms/step - loss: 0.0069 - accuracy: 0.1734\n","Epoch 21/30\n","185/185 [==============================] - 10s 54ms/step - loss: 0.0067 - accuracy: 0.1735\n","Epoch 22/30\n","185/185 [==============================] - 10s 54ms/step - loss: 0.0064 - accuracy: 0.1736\n","Epoch 23/30\n","185/185 [==============================] - 10s 54ms/step - loss: 0.0059 - accuracy: 0.1737\n","Epoch 24/30\n","185/185 [==============================] - 10s 54ms/step - loss: 0.0061 - accuracy: 0.1737\n","Epoch 25/30\n","185/185 [==============================] - 10s 54ms/step - loss: 0.0055 - accuracy: 0.1738\n","Epoch 26/30\n","185/185 [==============================] - 10s 54ms/step - loss: 0.0057 - accuracy: 0.1738\n","Epoch 27/30\n","185/185 [==============================] - 10s 54ms/step - loss: 0.0055 - accuracy: 0.1737\n","Epoch 28/30\n","185/185 [==============================] - 10s 54ms/step - loss: 0.0050 - accuracy: 0.1739\n","Epoch 29/30\n","185/185 [==============================] - 10s 54ms/step - loss: 0.0052 - accuracy: 0.1738\n","Epoch 30/30\n","185/185 [==============================] - 10s 54ms/step - loss: 0.0048 - accuracy: 0.1739\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7d9676326c20>"]},"metadata":{},"execution_count":58}]},{"cell_type":"code","source":["def new_evaluate(sentence):\n","  # 입력 문장에 대한 전처리\n","  sentence = preprocess_sentence(sentence)\n","\n","  # 입력 문장에 시작 토큰과 종료 토큰을 추가\n","  sentence = tf.expand_dims(\n","      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n","\n","  output = tf.expand_dims(START_TOKEN, 0)\n","\n","  # 디코더의 예측 시작\n","  for i in range(MAX_LENGTH):\n","    predictions = new_model(inputs=[sentence, output], training=False)\n","\n","    # 현재 시점의 예측 단어를 받아온다.\n","    predictions = predictions[:, -1:, :]\n","    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n","\n","    # 만약 현재 시점의 예측 단어가 종료 토큰이라면 예측을 중단\n","    if tf.equal(predicted_id, END_TOKEN[0]):\n","      break\n","\n","    # 현재 시점의 예측 단어를 output(출력)에 연결한다.\n","    # output은 for문의 다음 루프에서 디코더의 입력이 된다.\n","    output = tf.concat([output, predicted_id], axis=-1)\n","\n","  # 단어 예측이 모두 끝났다면 output을 리턴.\n","  return tf.squeeze(output, axis=0)\n"],"metadata":{"id":"hZnf1U1k4yXH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def new_predict(sentence):\n","  prediction = new_evaluate(sentence)\n","\n","  # prediction == 디코더가 리턴한 챗봇의 대답에 해당하는 정수 시퀀스\n","  # tokenizer.decode()를 통해 정수 시퀀스를 문자열로 디코딩.\n","  predicted_sentence = tokenizer.decode(\n","      [i for i in prediction if i < tokenizer.vocab_size])\n","\n","  print('Input: {}'.format(sentence))\n","  print('Output: {}'.format(predicted_sentence))\n","  tts = gTTS(\n","    text = predicted_sentence,\n","    lang =\"ko\", slow=False\n","    )\n","  tts.save(\"./chatbot_answer.mp3\")\n","  audio_path = \"./chatbot_answer.mp3\"\n","  chat_answer = Audio(audio_path)\n","\n","  return Audio(audio_path)\n"],"metadata":{"id":"qvkZ_Fjn6jtK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["while True:\n","  question = input()\n","  if question == \"끝\":\n","    break\n","  else:\n","    new_predict(question)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":405},"id":"Vdp5_KDvfOr-","outputId":"eace2ca3-3919-43c9-ba68-7be6a6ecff5f"},"execution_count":null,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-61-fe54eeb12f09>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mquestion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mquestion\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"끝\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"]}]}]}